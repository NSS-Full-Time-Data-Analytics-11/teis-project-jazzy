{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41164840",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/all_evals.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b2b28",
   "metadata": {},
   "source": [
    "Remove code columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82794df",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_cols = []\n",
    "pattern = re.compile('Code')\n",
    "\n",
    "for col in data.columns:\n",
    "    if re.search(pattern,col):\n",
    "        code_cols.append(col)\n",
    "#end\n",
    "\n",
    "data = data.drop(columns = code_cols)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a45581",
   "metadata": {},
   "source": [
    "Get rid of duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ea164",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[~data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7907cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978239a0",
   "metadata": {},
   "source": [
    "Clean up RDI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDI = re.compile('RDI') # r'RDI'\n",
    "pattern = r'\\d{1,2}\\/90'\n",
    "#new_vals = []\n",
    "#new_cols = {}\n",
    "\n",
    "for col in data.columns:\n",
    "    if re.search(RDI,col):\n",
    "        print('NEW COLUMN:',col)\n",
    "        ind = 0\n",
    "        \n",
    "        for value in data[col]:\n",
    "            print('Compare',value,'to',data[col][ind])\n",
    "            \n",
    "            if re.match(pattern,str(value)):\n",
    "                new_val = str(value)[:-3]\n",
    "                data.loc[ind,col] = int(new_val)\n",
    "                print(ind, 'Match', new_val)\n",
    "                \n",
    "            elif (str(value)[0] == '<') or (str(value)[0] == '>'):\n",
    "                new_val = str(value)[1:-3]\n",
    "                data.loc[ind,col] = int(new_val)\n",
    "                print(ind, '<>', new_val)\n",
    "                \n",
    "            elif type(value) == float:\n",
    "                new_vals.append(np.nan)\n",
    "                print(ind, 'NaN', new_val)\n",
    "                \n",
    "            else:\n",
    "                date = datetime.datetime.strptime(value, '%b-%y')\n",
    "                new_val = str(date.month)\n",
    "                data.loc[ind,col] = int(new_val)\n",
    "                print(ind, 'date', new_val)\n",
    "            #end\n",
    "            \n",
    "            ind += 1\n",
    "                \n",
    "        new_cols[col] = new_vals\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1131e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c39158",
   "metadata": {},
   "source": [
    "Clean up other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654762d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473b777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_patterns = ['Percentile', 'PR', 'AE', 'NCE']\n",
    "\n",
    "#j = 0\n",
    "for word in col_patterns:\n",
    "    pattern = re.compile(word)\n",
    "\n",
    "    for col in data.columns:\n",
    "        if re.search(pattern,col):\n",
    "            print('NEW COLUMN:',col)\n",
    "            ind = 0\n",
    "\n",
    "            for value in data[col]:\n",
    "                #print('j is:',j)\n",
    "                print('Compare',value,'to',data[col][ind])\n",
    "                \n",
    "                try:\n",
    "                    if (str(value)[0] == '<') or (str(value)[0] == '>'):\n",
    "                        print('Start: <>')\n",
    "                        new_val = str(value)[1:]\n",
    "                        data.loc[ind,col] = float(new_val)\n",
    "                        print(ind, '<>', value, '=>',new_value)\n",
    "                \n",
    "                    elif value == '':\n",
    "                        print('Start: Blank')\n",
    "                        new_val = np.nan\n",
    "                        data.loc[ind,col] = new_val\n",
    "                        print(ind, 'Blank', value, '=>',new_val)\n",
    "                        \n",
    "                    elif np.isnan(float(value)):\n",
    "                        print('Start: Nan (try)')\n",
    "                        print(ind, 'NaN', value)\n",
    "\n",
    "                    else:\n",
    "                        print('Start: Number')\n",
    "                        new_val = float(value)\n",
    "                        data.loc[ind,col] = new_val\n",
    "                        print(ind, 'Number', value, '=>',new_val)\n",
    "                    \n",
    "                    ind += 1\n",
    "                        \n",
    "                except:\n",
    "                    if type(value) == str:\n",
    "                        print(ind, 'String', value)\n",
    "                        ind += 1\n",
    "                        continue\n",
    "                    \n",
    "                    else:\n",
    "                        print('Start: NaN (except)')\n",
    "                        data.loc[ind,col] = np.nan\n",
    "                        print(ind, 'NaN', value)\n",
    "                    \n",
    "                    ind += 1\n",
    "\n",
    "                #j += 1\n",
    "                #if j >20:\n",
    "                #    break\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "float('<20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8fede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27355e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[0,'Adaptive Percentile Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e972be8",
   "metadata": {},
   "source": [
    "### Data is now clean!\n",
    "\n",
    "Next, let's create sub-dataframes based on what domain the column is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58428f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57851374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_data(data, domain):\n",
    "    \n",
    "    pattern = re.compile(domain)\n",
    "    \n",
    "    new_cols = []\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if re.search(pattern,col):\n",
    "            new_cols.append(col)\n",
    "    #end\n",
    "    \n",
    "    new_df = data[new_cols]\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['Adaptive','Social','Communication','Motor','Cognitive','Total']\n",
    "df_dict = {}\n",
    "\n",
    "for domain in domains:\n",
    "    new_df = slice_data(data,domain)\n",
    "    df_dict[domain] = new_df\n",
    "#end\n",
    "\n",
    "print(df_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7644142",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt = df_dict['Adaptive']\n",
    "soc   = df_dict['Social']\n",
    "comm  = df_dict['Communication']\n",
    "motor = df_dict['Motor']\n",
    "cogn  = df_dict['Cognitive']\n",
    "total = df_dict['Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c97078",
   "metadata": {},
   "source": [
    "We have now sliced the data based on domain! Now let's tackle the questions.\n",
    "\n",
    "## 1. In which domains (and sub-domains) are children performing highest and lowest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df3176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b096d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adapt_0 = adapt.fillna(0)\n",
    "adapt_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f700e4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(adapt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f754a",
   "metadata": {},
   "source": [
    "Replacing nulls with 0's impacts the last few columns the most, skewing the average. As such, I won't be replacing the null values for the rest of the dataframes.\n",
    "\n",
    "Also, several columns are missing from the describe table. This is because the rows datatypes are objects, not numeric. So I have to fix those columns before we move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7507a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adapt2 = adapt.drop(columns = ['Adaptive 95% Confidence Interval', 'Adaptive-Self Care CSS 90%', 'Adaptive-Personal Responsibility CSS 90%'])\n",
    "adapt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=0\n",
    "for value in adapt2['Adaptive RDI']:\n",
    "    print(ind,value,'\\t',str(value)[:-3])\n",
    "    adapt2.loc[ind,'Adaptive RDI'] = str(value)[:-3]\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8392bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adapt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef2a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adapt2 = adapt2.replace('<0.1','0.1').replace('<1','1').replace('>99','99').replace('',0)\n",
    "adapt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f094a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adapt2.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'123456789'[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3479cb8",
   "metadata": {},
   "source": [
    "This has become tedious to drop the columns I don't want. I'm going to define a nenw function that will only give me columns I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_numeric_data(data, domain):\n",
    "    date    = re.compile('Date')\n",
    "    percent = re.compile('%')\n",
    "    examine = re.compile('Examiner')\n",
    "    \n",
    "    pattern = re.compile(domain)\n",
    "    \n",
    "    new_cols = []\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if (re.search(pattern,col)):\n",
    "            if (not re.search(date,col)) & (not re.search(percent,col)) & (not re.search(examine,col)):\n",
    "                new_cols.append(col)\n",
    "    #end\n",
    "    \n",
    "    new_df = data[new_cols]\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt3 = slice_numeric_data(data, 'Adaptive')\n",
    "adapt3.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fc85a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adapt3.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f82f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "\n",
    "for domain in domains:\n",
    "    new_df = slice_numeric_data(data,domain)\n",
    "    df_dict[domain] = new_df\n",
    "#end\n",
    "\n",
    "print(df_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt = df_dict['Adaptive']\n",
    "soc   = df_dict['Social']\n",
    "comm  = df_dict['Communication']\n",
    "motor = df_dict['Motor']\n",
    "cogn  = df_dict['Cognitive']\n",
    "total = df_dict['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ce69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17245db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt.replace('<1','1').replace('>99','99').replace('<24','24')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1487d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
